apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ingest-clinvar-archive
spec:
  templates:
    - name: main
      inputs:
        parameters:
          - name: archive-path
          - name: gcs-prefix
      dag:
        tasks:
          # 1) Generate a PVC to hold the raw XML.
          - name: generate-download-volume
            templateRef:
              name: generate-pvc
              template: main
            arguments:
              parameters:
                - name: name-prefix
                  value: ftp-download
                - name: size
                  value: '{{ .Values.volumes.downloadSize }}'
                - name: storage-class
                  value: '{{ .Values.volumes.storageClass }}'
          # 2) Download the raw XML onto the new PVC.
          {{- $downloadPvc := "{{tasks.generate-download-volume.outputs.parameters.pvc-name}}" }}
          {{- $localXmlName := "ClinVarRelease.xml" }}
          - name: download-archive
            dependencies: [generate-download-volume]
            templateRef:
              name: download-ftp-file
              template: main
            arguments:
              parameters:
                - name: ftp-site
                  value: 'ftp.ncbi.nlm.nih.gov'
                - name: ftp-path
                  value: 'pub/clinvar/xml/clinvar_variation/{{ "{{inputs.parameters.archive-path}}" }}'
                - name: local-path
                  value: '{{ $localXmlName }}'
                - name: pvc-name
                  value: '{{ $downloadPvc }}'
          # 3a) Upload the raw XML to GCS.
          - name: upload-raw-archive
            dependencies: [download-archive]
            templateRef:
              name: rsync-to-gcs
              template: main
            arguments:
              parameters:
                - name: pvc-name
                  value: '{{ $downloadPvc }}'
                - name: local-prefix
                  value: ''
                - name: gcs-bucket
                  value: '{{ .Values.gcs.bucketName }}'
                - name: gcs-prefix
                  value: '{{ "{{inputs.parameters.gcs-prefix}}" }}/raw'
                - name: max-concurrent-uploads
                  value: '1'
          # 3b) Generate a PVC to hold extracted JSON-list files.
          - name: generate-extraction-volume
            # Don't generate the PVC until we need it.
            dependencies: [download-archive]
            templateRef:
              name: generate-pvc
              template: main
            arguments:
              parameters:
                - name: name-prefix
                  value: extracted-json
                - name: size
                  value: '{{ .Values.volumes.extractSize }}'
                - name: storage-class
                  value: '{{ .Values.volumes.storageClass }}'
          {{- $extractionPvc := "{{tasks.generate-extraction-volume.outputs.parameters.pvc-name}}" }}
          # 4) Extract raw XML to JSON-list.
          - name: extract-xml
            dependencies: [generate-extraction-volume]
            templateRef:
              name: extract-xml-to-json
              template: main
            arguments:
              parameters:
                - name: input-pvc-name
                  value: '{{ $downloadPvc }}'
                - name: input-xml-path
                  value: '{{ $localXmlName }}'
                - name: output-pvc-name
                  value: '{{ $extractionPvc }}'
          # 5a) Upload JSON-list data to GCS.
          - name: upload-extracted-archive
            dependencies: [extract-xml]
            templateRef:
              name: rsync-to-gcs
              template: main
            arguments:
              parameters:
                - name: pvc-name
                  value: '{{ $extractionPvc }}'
                - name: local-prefix
                  value: VariationArchive
                - name: gcs-bucket
                  value:  '{{ .Values.gcs.bucketName }}'
                - name: gcs-prefix
                  value: '{{ "{{inputs.parameters.gcs-prefix}}" }}/raw/VariationArchive'
                - name: max-concurrent-uploads
                  value: '2'
          # 5b) Extract clinvar release date.
          - name: extract-release-date
            dependencies: [extract-xml]
            templateRef:
              name: extract-clinvar-release-date
              template: main
            arguments:
              parameters:
                - name: pvc-name
                  value: '{{ $extractionPvc }}'
                - name: file-path
                  value: 'ClinVarVariationRelease/part-1.json'
          # 6) Ingest raw XML blob from GCS to Jade Data Repo.
          - name: ingest-raw-xml
            dependencies: [upload-raw-archive, extract-release-date]
            templateRef:
              name: ingest-file
              template: main
            arguments:
              parameters:
                {{- with .Values.repo }}
                - name: url
                  value: '{{ .url }}'
                - name: dataset-id
                  value: '{{ .datasetId }}'
                - name: profile-id
                  value: '{{ .profileId }}'
                - name: timeout
                  value: '{{ .pollTimeout }}'
                - name: sa-secret
                  value: '{{ .accessKey.secretName }}'
                - name: sa-secret-key
                  value: '{{ .accessKey.secretKey }}'
                {{- end }}
                - name: target-path
                  value: '{{ "/{{tasks.extract-release-date.outputs.result}}.xml" }}'
                - name: gcs-bucket
                  value: '{{ .Values.gcs.bucketName }}'
                - name: gcs-file-path
                  value: '{{ "{{inputs.parameters.gcs-prefix}}" }}/raw/{{ $localXmlName }}'
          # 7) Stage a release_history object in GCS
          - name: stage-release-history
            dependencies: [extract-release-date, ingest-raw-xml]
            templateRef:
              name: create-json-object
              template: main
            # WHEN the file does not already exist in the repo, THEN we can expect a drs-id for a file
            when: '{{ "{{tasks.ingest-raw-xml.outputs.parameters.file-exists}} == false" }}'
            arguments:
              parameters:
                - name: release-date
                  value: '{{ "{{tasks.extract-release-date.outputs.result}}" }}'
                - name: archive-path
                  value: '{{ "{{tasks.ingest-raw-xml.outputs.parameters.file-id}}" }}'
                - name: upload-path
                  value: '{{ printf "gs://%s/{{inputs.parameters.gcs-prefix}}/processed/release_history/" .Values.gcs.bucketName }}'
          # 8) Run Dataflow on uploaded JSON.
          - name: process-archive
            dependencies: [upload-extracted-archive]
            templateRef:
              name: run-dataflow
              template: main
            arguments:
              parameters:
                - name: gcs-bucket
                  value: '{{ .Values.gcs.bucketName }}'
                - name: input-prefix
                  value: '{{ "{{inputs.parameters.gcs-prefix}}" }}/raw'
                - name: output-prefix
                  value: '{{ "{{inputs.parameters.gcs-prefix}}" }}/processed'
          {{- $datasetName := printf "%s_%s" "monster_staging_data" (include "argo.timestamp" .) }}
          # 9) Create a dataset
          - name: create-dataset
            dependencies: [process-archive]
            templateRef:
              name: create-dataset
              template: main
            arguments:
              parameters:
                - name: dataset-name
                  value: {{ $datasetName }}
                - name: bq-project
                  value: '{{ .Values.bigquery.stagingData.project }}'
                - name: dataset-description
                  value: 'Dataset used by the Monster team for ingest ETL'
                - name: dataset-expiration
                  value: 604800000
          # 10) Diff generated data against existing data
          - name: diff-tables
            dependencies: [process-archive, create-dataset]
            templateRef:
              name: diff-table
              template: main
            arguments:
              parameters:
                - name: table-name
                  value: '{{ "{{item}}" }}'
                - name: gcs-bucket
                  value: '{{ .Values.gcs.bucketName }}'
                - name: input-prefix
                  value: '{{ "{{inputs.parameters.gcs-prefix}}/processed/{{item}}" }}'
                - name: old-ids-output-prefix
                  value: '{{ "{{inputs.parameters.gcs-prefix}}/old-ids/{{item}}" }}'
                - name: new-rows-output-prefix
                  value: '{{ "{{inputs.parameters.gcs-prefix}}/new-rows/{{item}}" }}'
                - name: staging-bq-project
                  value: '{{ .Values.bigquery.stagingData.project }}'
                - name: staging-bq-dataset
                  value: {{ $datasetName }}
                {{- with .Values.bigquery.jadeData }}
                - name: jade-bq-project
                  value: '{{ .project }}'
                - name: jade-bq-dataset
                  value: '{{ .dataset }}'
                {{- end }}
            withItems:
              - clinical_assertion
              - clinical_assertion_observation
              - clinical_assertion_trait
              - clinical_assertion_trait_set
              - clinical_assertion_variation
              - gene
              - gene_association
              - rcv_accession
              - submission
              - submitter
              - trait
              - trait_mapping
              - trait_set
              - variation
              - variation_archive
          # 11) Ingest tables into the Jade Data Repo
          - name: ingest-tables
            dependencies: [diff-tables]
            templateRef:
              name: ingest-table
              template: main
            arguments:
              parameters:
                {{- with .Values.repo }}
                - name: url
                  value: '{{ .url }}'
                - name: dataset-id
                  value: '{{ .datasetId }}'
                - name: timeout
                  value: '{{ .pollTimeout }}'
                - name: sa-secret
                  value: '{{ .accessKey.secretName }}'
                - name: sa-secret-key
                  value: '{{ .accessKey.secretKey }}'
                {{- end }}
                - name: gcs-bucket
                  value: '{{ .Values.gcs.bucketName }}'
                - name: gcs-prefix
                  value: '{{ "{{inputs.parameters.gcs-prefix}}/new-rows/{{item}}" }}'
                - name: table-name
                  value: '{{ "{{item}}" }}'
            withItems:
              - clinical_assertion
              - clinical_assertion_observation
              - clinical_assertion_trait
              - clinical_assertion_trait_set
              - clinical_assertion_variation
              - gene
              - gene_association
              - rcv_accession
              - submission
              - submitter
              - trait
              - trait_mapping
              - trait_set
              - variation
              - variation_archive
