apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ingest-processed-archive
spec:
  entrypoint: main
  serviceAccountName: {{ .Values.serviceAccount.k8sName }}
  templates:
    ##
    ## Entrypoint for ingesting the outputs of a processed ClinVar archive.
    ##
    ## Idempotent; will not re-ingest or re-delete rows if the state already
    ## matches in the Jade repository.
    ##
    - name: main
      inputs:
        parameters:
          - name: gcs-prefix
          {{- $gcsPrefix := "{{inputs.parameters.gcs-prefix}}" }}
          - name: release-date
          {{- $releaseDate := "{{inputs.parameters.release-date}}" }}
          - name: publish-kafka
          {{- $publishKafka := "{{inputs.parameters.publish-kafka}}" }}
          - name: publish-snapshot
          {{- $publishSnapshot := "{{inputs.parameters.publish-snapshot}}" }}
      # Limit to processing 1 table at a time to avoid lock failures in Jade.
      parallelism: 1
      dag:
        tasks:
          # Create a dataset to store intermediate outputs of ETL jobs.
          {{- $datasetName := printf "%s_%s" .Values.staging.bigquery.datasetPrefix $gcsPrefix }}
          - name: create-dataset
            templateRef:
              name: {{ .Values.argoTemplates.createBQDataset.name }}
              template: main
            arguments:
              parameters:
                - name: dataset-name
                  value: {{ $datasetName | quote }}
                {{- with .Values.staging.bigquery }}
                - name: bq-project
                  value: {{ .project }}
                - name: dataset-description
                  value: {{ .description }}
                - name: dataset-expiration
                  value: {{ .expiration }}
                {{- end }}

          # Write the archive's release date into ClinGen's bucket.
          - name: write-release-date
            template: stage-release-date
            arguments:
              parameters:
                - name: gcs-prefix
                  value: {{ $gcsPrefix | quote }}
                - name: release-date
                  value: {{ $releaseDate | quote }}

          # Loop over all tables, syncing state in Jade to match data staged in GCS.
          - name: process-tables
            dependencies: [create-dataset]
            withItems:
              - clinical_assertion
              - clinical_assertion_observation
              - clinical_assertion_trait
              - clinical_assertion_trait_set
              - clinical_assertion_variation
              - gene
              - gene_association
              - rcv_accession
              - submission
              - submitter
              - trait
              - trait_mapping
              - trait_set
              - variation
              - variation_archive
            template: process-table
            arguments:
              parameters:
                - name: dataset-name
                  value: {{ $datasetName | quote }}
                - name: gcs-prefix
                  value: {{ $gcsPrefix | quote }}
                - name: table-name
                  value: {{ "{{item}}" | quote }}
            {{- $summary := "{{tasks.process-tables.outputs.parameters}}" }}

          - name: notify-clingen
            dependencies: [process-tables]
            when: {{ printf "%s == true" $publishKafka | quote }}
            template: notify-clingen-kafka
            arguments:
              parameters:
                - name: release-date
                  value: {{ $releaseDate | quote }}
                - name: ingest-summary
                  value: {{ $summary | quote }}

          - name: publish-snapshot
            dependencies: [process-tables]
            when: {{ printf "%s == true" $publishSnapshot | quote }}
            template: create-snapshot
            arguments:
              parameters:
                - name: release-date
                  value: {{ $releaseDate | quote }}

    ##
    ## Update the Jade state of a single table to match data staged in GCS.
    ##
    ## Also extracts a ClinGen-compatible representation of the delta between
    ## Jade and staging into a separate bucket.
    ##
    - name: process-table
      inputs:
        parameters:
          - name: dataset-name
          {{- $datasetName := "{{inputs.parameters.dataset-name}}" }}
          - name: gcs-prefix
          {{- $gcsPrefix := "{{inputs.parameters.gcs-prefix}}" }}
          - name: table-name
          {{- $tableName := "{{inputs.parameters.table-name}}" }}
      dag:
        tasks:
          # Diff staged data against previously-ingested state.
          {{- $newRowsPrefix := printf "%s/new-rows/%s" $gcsPrefix $tableName }}
          {{- $oldIdsPrefix := printf "%s/old-ids/%s" $gcsPrefix $tableName }}
          - name: diff-table
            templateRef:
              name: {{ .Values.argoTemplates.diffBQTable.name }}
              template: main
            arguments:
              parameters:
                - name: table-name
                  value: {{ $tableName | quote }}
                - name: gcs-bucket
                  value: {{ .Values.staging.gcsBucket }}
                - name: input-prefix
                  value: {{ printf "%s/processed/%s" $gcsPrefix $tableName | quote }}
                - name: old-ids-output-prefix
                  value: {{ $oldIdsPrefix | quote }}
                - name: new-rows-output-prefix
                  value: {{ $newRowsPrefix | quote }}
                - name: staging-bq-project
                  value: {{ .Values.staging.bigquery.project }}
                - name: staging-bq-dataset
                  value: {{ $datasetName | quote }}
                - name: jade-bq-project
                  value: {{ .Values.jade.dataProject }}
                - name: jade-bq-dataset
                  value: {{ printf "datarepo_%s" .Values.jade.datasetName }}
            {{- $joinTable := "{{tasks.diff-table.outputs.parameters.join-table-name}}" }}
            {{- $shouldAppend := "{{tasks.diff-table.outputs.parameters.rows-to-append-count}} > 0" }}
            {{- $shouldDelete := "{{tasks.diff-table.outputs.parameters.ids-to-delete-count}} > 0" }}

          # Soft-delete IDs of outdated rows.
          - name: soft-delete-table
            dependencies: [diff-table]
            when: {{ $shouldDelete | quote }}
            templateRef:
              name: {{ .Values.argoTemplates.softDeleteTable.name }}
              template: main
            arguments:
              parameters:
                - name: table-name
                  value: {{ $tableName | quote }}
                - name: gcs-prefix
                  value: {{ $oldIdsPrefix | quote }}
                - name: gcs-bucket
                  value: {{ .Values.staging.gcsBucket }}
                {{- with .Values.jade }}
                - name: url
                  value: {{ .url }}
                - name: dataset-id
                  value: {{ .datasetId }}
                - name: timeout
                  value: {{ .pollTimeout }}
                - name: sa-secret
                  value: {{ .accessKey.secretName }}
                - name: sa-secret-key
                  value: {{ .accessKey.secretKey }}
                {{- end }}

          # Append rows with new data.
          - name: ingest-table
            dependencies: [diff-table, soft-delete-table]
            when: {{ $shouldAppend | quote }}
            templateRef:
              name:  {{ .Values.argoTemplates.ingestTable.name }}
              template: main
            arguments:
              parameters:
                - name: table-name
                  value: {{ $tableName | quote }}
                - name: gcs-bucket
                  value: {{ .Values.staging.gcsBucket }}
                - name: gcs-prefix
                  value: {{ $newRowsPrefix | quote }}
                {{- with .Values.jade }}
                - name: url
                  value: {{ .url }}
                - name: dataset-id
                  value: {{ .datasetId }}
                - name: timeout
                  value: {{ .pollTimeout }}
                - name: sa-secret
                  value: {{ .accessKey.secretName }}
                - name: sa-secret-key
                  value: {{ .accessKey.secretKey }}
                {{- end }}

          # Build the export prefixes for the table's ClinGen data.
          # NOTE: This step is a convenience to make the table-name + gcs-prefix
          # slurpable by the DAG's outputs.valueFrom (Argo doesn't support
          # passing inputs as outputs???), which is needed for downstream publishing.
          - name: build-export-paths
            template: build-export-paths
            arguments:
              parameters:
                - name: table-name
                  value: {{ $tableName | quote }}
                - name: gcs-prefix
                  value: {{ $gcsPrefix | quote }}
            {{- $createdPath := "{{tasks.build-export-paths.outputs.parameters.created-path}}" }}
            {{- $updatedPath := "{{tasks.build-export-paths.outputs.parameters.updated-path}}" }}
            {{- $deletedPath := "{{tasks.build-export-paths.outputs.parameters.deleted-path}}" }}

          # Export new rows to GCS for ClinGen
          - name: generate-new-rows-table
            dependencies: [diff-table]
            template: query-full-rows
            arguments:
              parameters:
                - name: bq-dataset
                  value: {{ $datasetName | quote }}
                - name: join-table-name
                  value: {{ $joinTable | quote }}
                - name: table-name
                  value: {{ $tableName | quote }}
                - name: query-type
                  value: new_rows
            {{- $newRowsTable := "{{tasks.generate-new-rows-table.outputs.result}}" }}

          - name: export-new-rows-table
            dependencies: [generate-new-rows-table, build-export-paths]
            templateRef:
              name: {{ .Values.argoTemplates.exportBQTable.name }}
              template: main
            arguments:
              parameters:
                - name: bq-project
                  value: {{ .Values.staging.bigquery.project }}
                - name: bq-dataset
                  value: {{ $datasetName | quote }}
                - name: bq-table
                  value: {{ $newRowsTable | quote }}
                - name: output-format
                  value: NEWLINE_DELIMITED_JSON
                - name: gcs-bucket
                  value: {{ .Values.clingen.gcsBucket }}
                - name: gcs-prefix
                  value: {{ $createdPath | quote }}
            {{- $createdCount := "{{tasks.export-new-rows-table.outputs.parameters.row-count}}" }}

          # Export updated rows to GCS for ClinGen
          - name: generate-updated-rows-table
            dependencies: [diff-table]
            template: query-full-rows
            arguments:
              parameters:
                - name: bq-dataset
                  value: {{ $datasetName | quote }}
                - name: join-table-name
                  value: {{ $joinTable | quote }}
                - name: table-name
                  value: {{ $tableName | quote }}
                - name: query-type
                  value: updates
            {{- $updatesTable := "{{tasks.generate-updated-rows-table.outputs.result}}" }}

          - name: export-updated-rows-table
            dependencies: [generate-updated-rows-table, build-export-paths]
            templateRef:
              name: {{ .Values.argoTemplates.exportBQTable.name }}
              template: main
            arguments:
              parameters:
                - name: bq-project
                  value: {{ .Values.staging.bigquery.project }}
                - name: bq-dataset
                  value: {{ $datasetName | quote }}
                - name: bq-table
                  value: {{ $updatesTable | quote }}
                - name: output-format
                  value: NEWLINE_DELIMITED_JSON
                - name: gcs-bucket
                  value: {{ .Values.clingen.gcsBucket }}
                - name: gcs-prefix
                  value: {{ $updatedPath | quote }}
            {{- $updatedCount := "{{tasks.export-updated-rows-table.outputs.parameters.row-count}}" }}

          # Export deleted row keys to GCS for ClinGen
          - name: generate-deleted-rows-table
            dependencies: [diff-table]
            template: query-pk-deletes
            arguments:
              parameters:
                - name: bq-dataset
                  value: {{ $datasetName | quote }}
                - name: join-table-name
                  value: {{ $joinTable | quote }}
                - name: table-name
                  value: {{ $tableName | quote }}
            {{- $deletionsTable := "{{tasks.generate-deleted-rows-table.outputs.result}}" }}

          - name: export-deleted-rows-table
            dependencies: [generate-deleted-rows-table, build-export-paths]
            templateRef:
              name: {{ .Values.argoTemplates.exportBQTable.name }}
              template: main
            arguments:
              parameters:
                - name: bq-project
                  value: {{ .Values.staging.bigquery.project }}
                - name: bq-dataset
                  value: {{ $datasetName | quote }}
                - name: bq-table
                  value: {{ $deletionsTable | quote }}
                - name: output-format
                  value: NEWLINE_DELIMITED_JSON
                - name: gcs-bucket
                  value: {{ .Values.clingen.gcsBucket }}
                - name: gcs-prefix
                  value: {{ $deletedPath | quote }}
            {{- $deletedCount := "{{tasks.export-deleted-rows-table.outputs.parameters.row-count}}" }}

      outputs:
        parameters:
          - name: created-prefix
            valueFrom:
              parameter: {{ $createdPath | quote }}
          - name: created-count
            valueFrom:
              parameter: {{ $createdCount | quote }}
          - name: updated-prefix
            valueFrom:
              parameter: {{ $updatedPath | quote }}
          - name: updated-count
            valueFrom:
              parameter: {{ $updatedCount | quote }}
          - name: deleted-prefix
            valueFrom:
              parameter: {{ $deletedPath | quote }}
          - name: deleted-count
            valueFrom:
              parameter: {{ $deletedCount | quote }}

    ##
    ## Plumbing task to get create/update/delete prefixes into a format
    ## that can thread through Argo's output parameters.
    ##
    - name: build-export-paths
      inputs:
        parameters:
          - name: table-name
          {{- $tableName := "{{inputs.parameters.table-name}}" }}
          - name: gcs-prefix
          {{- $gcsPrefix := "{{inputs.parameters.gcs-prefix}}"  }}
      script:
        # Image not important here, just need something w/ bash
        image: python:3-slim
        command: [bash]
        source: |
          set -euo pipefail

          for event in created updated deleted; do
            echo {{ $gcsPrefix }}/{{ $tableName }}/${event} > /${event}.txt
          done
      outputs:
        parameters:
          - name: created-path
            valueFrom:
              path: /created.txt
          - name: updated-path
            valueFrom:
              path: /updated.txt
          - name: deleted-path
            valueFrom:
              path: /deleted.txt


    {{- $schemaImage := printf "%s:%s" .Values.argoTemplates.diffBQTable.schemaImageName (default "latest" .Values.argoTemplates.diffBQTable.schemaImageVersion) }}
    # query-full-rows will be generic for both the new rows + updates
    - name: query-full-rows
      inputs:
        parameters:
          - name: table-name
          - name: join-table-name
          - name: bq-dataset
          - name: query-type
      script:
        image: {{ $schemaImage }}
        # layer of env variables to make the scripts more stand-alone and more compatible within editors
        env:
          - name: PROJECT
            value: {{ .Values.staging.bigquery.project }}
          - name: DATASET
            value: {{ "{{inputs.parameters.bq-dataset}}" | quote }}
          - name: INPUT_TABLE
            value: {{ "{{inputs.parameters.join-table-name}}" | quote }}
          - name: TABLE
            value: {{ "{{inputs.parameters.table-name}}" | quote }}
          - name: QUERY_TYPE
            value: {{ "{{inputs.parameters.query-type}}" | quote }}
        command: [bash]
        source: |
        {{- include "argo.render-lines" (.Files.Lines "scripts/clingen-temp-table-full-rows.sh") | indent 10 }}

    # query-pk-deletes to get primary keys of rows to be deleted
    - name: query-pk-deletes
      inputs:
        parameters:
          - name: table-name
          - name: join-table-name
          - name: bq-dataset
      script:
        image: {{ $schemaImage }}
        env:
          - name: PROJECT
            value: {{ .Values.staging.bigquery.project }}
          - name: DATASET
            value: {{ "{{inputs.parameters.bq-dataset}}" | quote }}
          - name: INPUT_TABLE
            value: {{ "{{inputs.parameters.join-table-name}}" | quote }}
          - name: TABLE
            value: {{ "{{inputs.parameters.table-name}}" | quote }}
        command: [bash]
        source: |
        {{- include "argo.render-lines" (.Files.Lines "scripts/clingen-temp-table-pk-deletes.sh") | indent 10 }}

    - name: stage-release-date
      inputs:
        parameters:
          - name: release-date
          {{- $releaseDate := "{{inputs.parameters.release-date}}" }}
          - name: gcs-prefix
          {{- $gcsPrefix := "{{inputs.parameters.gcs-prefix}}" }}
      script:
        image: google/cloud-sdk:slim
        command: [bash]
        {{- $uploadPath := printf "gs://%s/%s/" .Values.clingen.gcsBucket $gcsPrefix }}
        source: |
          echo "{{ $releaseDate }}" > release_date.txt
          gsutil cp release_date.txt {{ $uploadPath }}

    ##
    ## Send a Kafka message to ClinGen, pointing them at newly-ingested data.
    ##
    - name: notify-clingen-kafka
      inputs:
        parameters:
          - name: release-date
          {{- $releaseDate := "{{inputs.parameters.release-date}}" }}
          - name: ingest-summary
          {{- $ingestSummary := "{{inputs.parameters.ingest-summary}}" }}
      script:
        image: us.gcr.io/broad-dsp-gcr-public/clingen-notifier:1.0.0
        env:
          - name: RELEASE_DATE
            value: {{ $releaseDate | quote }}
          - name: GCS_BUCKET
            value: {{ .Values.clingen.gcsBucket }}
          - name: INGEST_SUMMARY
            value: {{ $ingestSummary | quote }}
          - name: KAFKA_TOPIC
            value: {{ .Values.clingen.kafka.topic }}
        envFrom:
          - secretRef:
              name: {{ .Values.clingen.kafka.secretName }}
        command: [python]
        source: |
        {{- include "argo.render-lines" (.Files.Lines "scripts/notify-clingen-kafka.py") | indent 10 }}

    ##
    ## Create a snapshot containing all live data in the ClinVar dataset.
    ##
    - name: create-snapshot
      inputs:
        parameters:
          - name: release-date
          {{- $releaseDate := "{{inputs.parameters.release-date}}" }}
      dag:
        tasks:
          - name: get-snapshot-name
            template: get-snapshot-name
            arguments:
              parameters:
                - name: release-date
                  value: {{ $releaseDate | quote }}
          {{- $snapshotName := "{{tasks.get-snapshot-name.outputs.result}}" }}

          - name: submit-job
            dependencies: [get-snapshot-name]
            template: submit-full-view-snapshot
            arguments:
              parameters:
                - name: snapshot-name
                  value: {{ $snapshotName | quote }}
          {{ $jobId := "{{tasks.submit-job.outputs.result}}" }}

          - name: poll-job
            dependencies: [submit-job]
            template: poll-ingest-job
            arguments:
              parameters:
                - name: job-id
                  value: {{ $jobId | quote }}
                {{- with .Values.jade }}
                - name: api-url
                  value: {{ .url }}
                - name: timeout
                  value: {{ .pollTimeout | quote }}
                - name: sa-secret
                  value: {{ .accessKey.secretName }}
                - name: sa-secret-key
                  value: {{ .accessKey.secretKey }}
                {{- end }}

    ##
    ## Transform a release-date into a TDR snapshot name.
    ##
    - name: get-snapshot-name
      inputs:
        parameters:
          - name: release-date
          {{- $releaseDate := "{{inputs.parameters.release-date}}" }}
      script:
        image: python:3-slim
        command: [python]
        source: |
          release_date = '{{ $releaseDate }}'
          print(f"clinvar_{release_date.replace('-', '_')}")

    ##
    ## Submit a job to the TDR which will create a snapshot of all live data in a dataset.
    ##
    - name: submit-full-view-snapshot
      inputs:
        parameters:
          - name: snapshot-name
          {{- $snapshotName := "{{inputs.parameters.snapshot-name}}" }}
      volumes:
        {{- with .Values.jade }}
        - name: sa-secret-volume
          secret:
            secretName: {{ .accessKey.secretName }}
      script:
        image: us.gcr.io/broad-dsp-gcr-public/monster-auth-req-py:1.0.1
        volumeMounts:
          - name: sa-secret-volume
            mountPath: /secret
        env:
          - name: API_URL
            value: {{ .url }}
          - name: DATASET_NAME
            value: {{ .datasetName }}
          - name: PROFILE_ID
            value: {{ .profileId }}
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: {{ printf "/secret/%s" .accessKey.secretKey }}
        {{- end }}
          - name: SNAPSHOT_NAME
            value: {{ $snapshotName | quote }}
        command: [python]
        source: |
        {{- include "argo.render-lines" (.Files.Lines "scripts/request-full-view-snapshot.py") | indent 10 }}

    ## Inject template used to poll TDR jobs.
    {{- include "argo.poll-ingest-job" . | indent 4 }}
