apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ingest-processed-archive
spec:
  templates:
    ##
    ## Entrypoint for ingesting the outputs of a processed ClinVar archive.
    ##
    ## Idempotent; will not re-ingest or re-delete rows if the state already
    ## matches in the Jade repository.
    ##
    - name: main
      inputs:
        parameters:
          - name: gcs-prefix
          {{- $gcsPrefix := "{{inputs.parameters.gcs-prefix}}" }}
      # Limit to processing 1 table at a time to avoid lock failures in Jade.
      parallelism: 1
      dag:
        tasks:
          # Create a dataset to store intermediate outputs of ETL jobs.
          {{- $datasetName := printf "%s_%s" .Values.bigquery.stagingData.datasetPrefix $gcsPrefix }}
          - name: create-dataset
            templateRef:
              name: {{ .Values.argoTemplates.createBQDataset.name }}
              template: main
            arguments:
              parameters:
                - name: dataset-name
                  value: {{ $datasetName }}
                {{- with .Values.bigquery.stagingData }}
                - name: bq-project
                  value: '{{ .project }}'
                - name: dataset-description
                  value: '{{ .description }}'
                - name: dataset-expiration
                  value: '{{ .expiration }}'
                {{- end }}

          # Loop over all tables, syncing state in Jade to match data staged in GCS.
          - name: process-tables
            dependencies: [create-dataset]
            withItems:
              - clinical_assertion
              - clinical_assertion_observation
              - clinical_assertion_trait
              - clinical_assertion_trait_set
              - clinical_assertion_variation
              - gene
              - gene_association
              - rcv_accession
              - submission
              - submitter
              - trait
              - trait_mapping
              - trait_set
              - variation
              - variation_archive
            template: process-table
            arguments:
              parameters:
                - name: dataset-name
                  value: '{{ $datasetName }}'
                - name: gcs-prefix
                  value: '{{ $gcsPrefix }}'
                - name: table-name
                  value: '{{ "{{item}}" }}'

    ##
    ## Update the Jade state of a single table to match data staged in GCS.
    ##
    ## Also extracts a ClinGen-compatible representation of the delta between
    ## Jade and staging into a separate bucket.
    ##
    - name: process-table
      inputs:
        parameters:
          - name: dataset-name
          {{- $datasetName := "{{inputs.parameters.dataset-name}}" }}
          - name: gcs-prefix
          {{- $gcsPrefix := "{{inputs.parameters.gcs-prefix}}" }}
          - name: table-name
          {{- $tableName := "{{inputs.parameters.table-name}}" }}
      dag:
        tasks:
          # Diff staged data against previously-ingested state.
          {{- $newRowsPrefix := printf "%s/new-rows/%s" $gcsPrefix $tableName }}
          {{- $oldIdsPrefix := printf "%s/old-ids/%s" $gcsPrefix $tableName }}
          - name: diff-table
            templateRef:
              name: {{ .Values.argoTemplates.diffBQTable.name }}
              template: main
            arguments:
              parameters:
                - name: table-name
                  value: '{{ $tableName }}'
                - name: gcs-bucket
                  value: '{{ .Values.parameters.gcs.bucketName }}'
                - name: input-prefix
                  value: '{{ printf "%s/processed/%s" $gcsPrefix $tableName }}'
                - name: old-ids-output-prefix
                  value: '{{ $oldIdsPrefix }}'
                - name: new-rows-output-prefix
                  value: '{{ $newRowsPrefix }}'
                - name: staging-bq-project
                  value: '{{ .Values.bigquery.stagingData.project }}'
                - name: staging-bq-dataset
                  value: '{{ $datasetName }}'
                - name: jade-bq-project
                  value: '{{ .Values.bigquery.jadeData.project }}'
                - name: jade-bq-dataset
                  value: '{{ .Values.bigquery.jadeData.dataset }}'
            {{- $joinTable := "{{tasks.diff-table.outputs.parameters.join-table-name}}" }}
            {{- $shouldAppend := "{{tasks.diff-table.outputs.parameters.rows-to-append-count}} > 0" }}
            {{- $shouldDelete := "{{tasks.diff-table.outputs.parameters.ids-to-delete-count}} > 0" }}

          # Append rows with new data.
          - name: ingest-table
            dependencies: [diff-table]
            when: '{{ $shouldAppend }}'
            templateRef:
              name:  {{ .Values.argoTemplates.ingestTable.name }}
              template: main
            arguments:
              parameters:
                - name: table-name
                  value: '{{ $tableName }}'
                - name: gcs-prefix
                  value: '{{ $newRowsPrefix }}'
                {{- with .Values.repo }}
                - name: url
                  value: '{{ .url }}'
                - name: dataset-id
                  value: '{{ .datasetId }}'
                - name: timeout
                  value: '{{ .pollTimeout }}'
                - name: sa-secret
                  value: '{{ .accessKey.secretName }}'
                - name: sa-secret-key
                  value: '{{ .accessKey.secretKey }}'
                {{- end }}

          # Soft-delete IDs of outdated rows.
          - name: soft-delete-table
            dependencies: [diff-table]
            when: '{{ $shouldDelete }}'
            templateRef:
              name: {{ .Values.argoTemplates.softDeleteTable.name }}
              template: main
            arguments:
              parameters:
                - name: table-name
                  value: '{{ $tableName }}'
                - name: gcs-prefix
                  value: '{{ $oldIdsPrefix }}'
                {{- with .Values.repo }}
                - name: url
                  value: '{{ .url }}'
                - name: dataset-id
                  value: '{{ .datasetId }}'
                - name: timeout
                  value: '{{ .pollTimeout }}'
                - name: sa-secret
                  value: '{{ .accessKey.secretName }}'
                - name: sa-secret-key
                  value: '{{ .accessKey.secretKey }}'
                {{- end }}

          # Export new rows to GCS for ClinGen
          - name: generate-new-rows-table
            dependencies: [diff-table]
            template: query-full-rows
            arguments:
              parameters:
                - name: bq-dataset
                  value: '{{ $datasetName }}'
                - name: join-table-name
                  value: '{{ $joinTable }}'
                - name: table-name
                  value: '{{ $tableName }}'
                - name: query-type
                  value: new_rows
            {{- $newRowsTable := "{{tasks.generate-new-rows-table.outputs.result}}" }}

          - name: export-new-rows-table
            dependencies: [generate-new-rows-table]
            templateRef:
              name: {{ .Values.argoTemplates.exportBQTable.name }}
              template: main
            arguments:
              parameters:
                - name: bq-project
                  value: '{{ .Values.bigquery.stagingData.project }}'
                - name: bq-dataset
                  value: '{{ $datasetName }}'
                - name: bq-table
                  value: '{{ $newRowsTable }}'
                - name: output-format
                  value: NEWLINE_DELIMITED_JSON
                - name: gcs-bucket
                  value: '{{ .Values.gcs.resultBucketName }}'
                - name: gcs-prefix
                  value: '{{ printf "%s/%s/creates" $gcsPrefix $tableName }}'

          # Export updated rows to GCS for ClinGen
          - name: generate-updated-rows-table
            dependencies: [diff-table]
            template: query-full-rows
            arguments:
              parameters:
                - name: bq-dataset
                  value: '{{ $datasetName }}'
                - name: join-table-name
                  value: '{{ $joinTable }}'
                - name: table-name
                  value: '{{ $tableName }}'
                - name: query-type
                  value: updates
            {{- $updatesTable := "{{tasks.generate-updated-rows-table.outputs.result}}" }}

          - name: export-updated-rows-table
            dependencies: [generate-updated-rows-table]
            templateRef:
              name: {{ .Values.argoTemplates.exportBQTable.name }}
              template: main
            arguments:
              parameters:
                - name: bq-project
                  value: '{{ .Values.bigquery.stagingData.project }}'
                - name: bq-dataset
                  value: '{{ $datasetName }}'
                - name: bq-table
                  value: '{{ $updatesTable }}'
                - name: output-format
                  value: NEWLINE_DELIMITED_JSON
                - name: gcs-bucket
                  value: '{{ .Values.gcs.resultBucketName }}'
                - name: gcs-prefix
                  value: '{{ printf "%s/%s/updates" $gcsPrefix $tableName }}'

          # Export deleted row keys to GCS for ClinGen
          - name: generate-deleted-rows-table
            dependencies: [diff-table]
            template: query-pk-deletes
            arguments:
              parameters:
                - name: bq-dataset
                  value: '{{ $datasetName }}'
                - name: join-table-name
                  value: '{{ $joinTable }}'
                - name: table-name
                  value: '{{ $tableName }}'
            {{- $deletionsTable := "{{tasks.generate-deleted-rows-table.outputs.result}}" }}

          - name: export-deleted-rows-table
            dependencies: [generate-deleted-rows-table]
            templateRef:
              name: {{ .Values.argoTemplates.exportBQTable.name }}
              template: main
            arguments:
              parameters:
                - name: bq-project
                  value: '{{ .Values.bigquery.stagingData.project }}'
                - name: bq-dataset
                  value: '{{ $datasetName }}'
                - name: bq-table
                  value: '{{ $deletionsTable }}'
                - name: output-format
                  value: NEWLINE_DELIMITED_JSON
                - name: gcs-bucket
                  value: '{{ .Values.gcs.resultBucketName }}'
                - name: gcs-prefix
                  value: '{{ printf "%s/%s/deletes" $gcsPrefix $tableName }}'

    {{- $schemaImage := printf "%s:%s" .Values.argoTemplates.diffBQTable.schemaImageName (default "latest" .Values.diffBQTable.schemaImageVersion) }}
    # query-full-rows will be generic for both the new rows + updates
    - name: query-full-rows
      inputs:
        parameters:
          - name: table-name
          - name: join-table-name
          - name: bq-dataset
          - name: query-type
      {{- include "argo.retry" . | indent 6 }}
      script:
        image: {{ $schemaImage }}
        # layer of env variables to make the scripts more stand-alone and more compatible within editors
        env:
          - name: PROJECT
            value: '{{ .Values.bigquery.stagingData.project }}'
          - name: DATASET
            value: '{{ "{{inputs.parameters.bq-dataset}}" }}'
          - name: INPUT_TABLE
            value: '{{ "{{inputs.parameters.join-table-name}}" }}'
          - name: TABLE
            value: '{{ "{{inputs.parameters.table-name}}" }}'
          - name: QUERY_TYPE
            value: '{{ "{{inputs.parameters.query-type}}" }}'
        command: [bash]
        source: |
        {{- include "argo.render-lines" (.Files.Lines "scripts/clingen-temp-table-full-rows.sh") | indent 10 }}

    # query-pk-deletes to get primary keys of rows to be deleted
    - name: query-pk-deletes
      inputs:
        parameters:
          - name: table-name
          - name: join-table-name
          - name: bq-dataset
      {{- include "argo.retry" . | indent 6 }}
      script:
        image: {{ $schemaImage }}
        env:
          - name: PROJECT
            value: '{{ .Values.bigquery.stagingData.project }}'
          - name: DATASET
            value: '{{ "{{inputs.parameters.bq-dataset}}" }}'
          - name: INPUT_TABLE
            value: '{{ "{{inputs.parameters.join-table-name}}" }}'
          - name: TABLE
            value: '{{ "{{inputs.parameters.table-name}}" }}'
        command: [bash]
        source: |
        {{- include "argo.render-lines" (.Files.Lines "scripts/clingen-temp-table-pk-deletes.sh") | indent 10 }}
