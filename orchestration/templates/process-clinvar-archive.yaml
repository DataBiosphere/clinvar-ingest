apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: process-clinvar-archive
spec:
  templates:
    ##
    ## Entrypoint for processing a ClinVar archive.
    ##
    ## Transfers the archive to GCS and processes it with Dataflow,
    ## outputting its release date.
    ##
    - name: main
      inputs:
        parameters:
          - name: archive-path
          {{- $archivePath := "{{inputs.parameters.archive-path}}" }}
          - name: gcs-prefix
          {{- $gcsPrefix := "{{inputs.parameters.gcs-prefix}}" }}
      dag:
        tasks:
          # Generate a PVC to hold the raw XML.
          - name: generate-download-volume
            templateRef:
              name: {{ .Values.argoTemplates.generatePVC.name }}
              template: main
            arguments:
              parameters:
                - name: name-prefix
                  value: ftp-download
                - name: size
                  value: '{{ .Values.volumes.downloadSize }}'
                - name: storage-class
                  value: '{{ .Values.volumes.storageClass }}'
            {{- $downloadPvc := "{{tasks.generate-download-volume.outputs.parameters.pvc-name}}" }}

          # Download the raw XML onto the new PVC.
          - name: download-archive
            dependencies: [generate-download-volume]
            templateRef:
              name: {{ .Values.argoTemplates.downloadFTPFile.name }}
              template: main
            arguments:
              - name: ftp-site
                value: 'ftp.ncbi.nlm.nih.gov'
              - name: ftp-path
                value: value: 'pub/clinvar/xml/clinvar_variation/{{ $archivePath }}'
              - name: local-path
                value: {{ include "clinvar.raw-archive-name "}}
              - name: pvc-name
                value: '{{ $downloadPvc }}'
              - name: memory
                value: '512Mi'
              - name: cpu
                value: '1000m'

          # Upload the raw XML to GCS.
          - name: upload-raw-archive
            dependencies: [download-archive]
            templateRef:
              name: {{ .Values.argoTemplates.gsutilRsync.name }}
              template: main
            arguments:
              parameters:
                - name: pvc-name
                  value: '{{ $downloadPvc }}'
                - name: local-prefix
                  value: ''
                - name: gcs-bucket
                  value: '{{ .Values.gcs.bucketName }}'
                - name: gcs-prefix
                  value: '{{ $gcsPrefix }}/raw'
                - name: memory
                  value: '1Gi'
                - name: cpu
                  value: '1000m'

          # Generate a PVC to hold extracted JSON-list files.
          - name: generate-extraction-volume
            # Don't generate the PVC until we need it.
            dependencies: [download-archive]
            templateRef:
              name: generate-pvc
              template: main
            arguments:
              parameters:
                - name: name-prefix
                  value: extracted-json
                - name: size
                  value: '{{ .Values.volumes.extractSize }}'
                - name: storage-class
                  value: '{{ .Values.volumes.storageClass }}'
            {{- $extractionPvc := "{{tasks.generate-extraction-volume.outputs.parameters.pvc-name}}" }}

          # Extract raw XML to JSON-list.
          - name: extract-xml
            dependencies: [generate-extraction-volume]
            templateRef:
              name: {{ .Values.xmlToJsonList.templateName }}
              template: main
            arguments:
              parameters:
                - name: input-pvc-name
                  value: '{{ $downloadPvc }}'
                - name: input-xml-path
                  value: {{ include "clinvar.raw-archive-name "}}
                - name: output-pvc-name
                  value: '{{ $extractionPvc }}'
                - name: objects-per-part
                  value: '1024'
                - name: gunzip
                  value: 'true'
                - name: memory-mib
                  value: '2560'
                - name: cpu-m
                  value: '1500'

          # Clean up the download PVC
          - name: delete-download-volume
            dependencies: [upload-raw-archive, extract-xml]
            templateRef:
              name: {{ .Values.argoTemplates.deletePVC.name }}
              template: main
            arguments:
              parameters:
                - name: pvc-name
                  value: '{{ $downloadPvc }}'

          # Upload extracted JSON-list data to GCS.
          - name: upload-extracted-archive
            dependencies: [extract-xml]
            templateRef:
              name: {{ .Values.argoTemplates.gsutilRsync.name }}
              template: main
            arguments:
              parameters:
                - name: pvc-name
                  value: '{{ $extractionPvc }}'
                - name: local-prefix
                  value: VariationArchive
                - name: gcs-bucket
                  value:  '{{ .Values.gcs.bucketName }}'
                - name: gcs-prefix
                  value: '{{ $gcsPrefix }}/raw/VariationArchive'
                - name: memory
                  value: '2Gi'
                - name: cpu
                  value: '2000m'

          # Read the archive's release date from JSON.
          - name: extract-release-date
            dependencies: [extract-xml]
            template: extract-release-date
            arguments:
              parameters:
                - name: pvc-name
                  value: '{{ $extractionPvc }}'
                - name: file-path
                  value: 'ClinVarVariationRelease/part-1.json'
            {{- $releaseDate := "{{tasks.extract-release-date.outputs.result}}" }}

          # Clean up the extraction PVC
          - name: delete-extraction-volume
            dependencies: [upload-extracted-archive, extract-release-date]
            templateRef:
              name: {{ .Values.argoTemplates.deletePVC.name }}
              template: main
            arguments:
              parameters:
                - name: pvc-name
                  value: '{{ $extractionPvc }}'

          # Use Dataflow to process the uploaded JSON-list
          - name: process-archive
            dependencies: [upload-extracted-archive]
            template: run-dataflow
            arguments:
              parameters:
                - name: gcs-prefix
                  value: '{{ $gcsPrefix }}'

        # Output the extracted release date so it can be used in following steps when
        # this workflow is launched by the over-arching orchestration pipeline.
        outputs:
          parameters:
            - name: release-date
              valueFrom:
                parameter: '{{ $releaseDate }}'

    ##
    ## Shim template used to extract the release date from
    ## the raw JSON extracted from a ClinVar archive.
    ##
    - name: extract-release-date
      inputs:
        parameters:
          - name: pvc-name
          - name: file-path
      volumes:
        - name: state
          persistentVolumeClaim:
            claimName: '{{ "{{inputs.parameters.pvc-name}}" }}'
            readOnly: true
      script:
        image: python:3-slim
        command: [python]
        volumeMounts:
          - name: state
            mountPath: /state
            readOnly: true
        source: |
          import json
          with open('/state/{{ "{{inputs.parameters.file-path}}" }}') as f:
            json_data = json.load(f)
          print(json_data["ClinVarVariationRelease"]["@ReleaseDate"])

    ##
    ## Template used to launch a Dataflow processing job on raw ClinVar data,
    ## transforming it to our target schema.
    ##
    - name: run-dataflow
      inputs:
        parameters:
          - name: gcs-prefix
          {{- $prefix := "{{inputs.parameters.gcs-prefix}}" }}
      container:
        {{- $version := default "latest" .Values.global.version }}
        image: us.gcr.io/broad-dsp-gcr-public/clinvar-transformation-pipeline:{{ $version }}
        command: []
        args:
          - --runner=dataflow
          {{- $bucket := .Values.gcs.bucketName }}
          - --inputPrefix=gs://{{ $bucket }}/{{ $prefix }}/raw
          - --outputPrefix=gs://{{ $bucket }}/{{ $prefix }}/processed
          {{- with .Values.dataflow }}
          - --project={{ .project }}
          - --region={{ .region }}
          - --tempLocation=gs://{{ .tmpBucketName }}/dataflow
          - --subnetwork=regions/{{ .region }}/subnetworks/{{ .subnetName }}
          - --serviceAccount={{ .workerAccount }}
          - --workerMachineType={{ .workerMachineType }}
          {{- with .autoscaling }}
          - --autoscalingAlgorithm=THROUGHPUT_BASED
          - --numWorkers={{ .minWorkers }}
          - --maxNumWorkers={{ .maxWorkers }}
          {{- end }}
          {{- if .useFlexRS }}
          - --flexRSGoal=COST_OPTIMIZED
          {{- else }}
          - --experiments=shuffle_mode=service
          {{- end }}
          {{- end }}
