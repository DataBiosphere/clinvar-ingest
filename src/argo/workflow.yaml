apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: clinvar-extraction-
spec:
  entrypoint: extract-latest-clinvar-release
  podGC:
    strategy: OnWorkflowSuccess
  volumes:
    - name: gcs-writer-key
      secret:
        secretName: "{{workflow.parameters.gcs-key-secret}}"
        items:
          - key: "{{workflow.parameters.gcs-key-name}}"
            path: "{{workflow.parameters.gcs-key-name}}"
  volumeClaimTemplates:
    - metadata:
        name: state-dir
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            # ClinVar releases are typically ~650Mi when gzipped, and extract to
            # ~7-8Gi. Throw in some extra for gsutil scratch space.
            storage: 10Gi
  arguments:
    parameters:
      - name: archive-path
        # NOTE: Relative to the clinvar_variation directory, to avoid downloading
        # one of the payloads with the older XML schema.
        value: weekly_release/ClinVarVariationRelease_00-latest_weekly.xml.gz
  templates:
    ## "Main" function for the extraction workflow.
    - name: extract-latest-clinvar-release
      steps:
        - - name: download-latest-weekly-release
            template: download-ftp-file
            arguments:
              parameters:
                - name: ftp-site
                  value: ftp.ncbi.nlm.nih.gov
                - name: ftp-path
                  value: pub/clinvar/xml/clinvar_variation/{{workflow.parameters.archive-path}}
                - name: local-path
                  value: ClinVarRelease.xml.gz
        - - name: extract-release
            template: extract-xml-to-json
            arguments:
              parameters:
                - name: xml-path
                  value: ClinVarRelease.xml.gz
                - name: output-path
                  value: extracted-clinvar-json
                - name: rows-per-output
                  value: 1024
        - - name: upload-extracted-release
            template: upload-to-gcs
            arguments:
              parameters:
                - name: local-path
                  value: extracted-clinvar-json
                - name: gcs-bucket
                  value: '{{workflow.parameters.output-gcs-bucket}}'
                - name: gcs-path
                  value: '{{workflow.parameters.output-gcs-prefix}}'
                - name: key-secret-volume
                  value: gcs-writer-key
                - name: key-secret-file
                  value: "{{workflow.parameters.gcs-key-name}}"

    ## Downloads a file from an FTP site onto a k8s volume.
    - name: download-ftp-file
      inputs:
        parameters:
          - name: ftp-site
          - name: ftp-path
          - name: local-path
      container:
        image: cirrusci/wget
        command: [wget]
        args:
          # Restart from any state
          - --continue
          # Reset the download connection if it goes idle for > 30 seconds.
          - --read-timeout=30
          - --output-document=/state/{{inputs.parameters.local-path}}
          - ftp://{{inputs.parameters.ftp-site}}/{{inputs.parameters.ftp-path}}
        volumeMounts:
          - name: state-dir
            mountPath: /state
        resources:
          requests:
            memory: 512Mi
            cpu: 1000m
          limits:
            memory: 512Mi
            cpu: 1000m
      retryStrategy:
        limit: 32

    ## Extracts a local XML payload into badger-fish JSON.
    - name: extract-xml-to-json
      inputs:
        parameters:
          - name: xml-path
          - name: output-path
          - name: rows-per-output
      container:
        image: us.gcr.io/broad-dsp-gcr-public/monster-xml-to-json-list:2.0.2
        command: []
        args:
          - --input=/state/{{inputs.parameters.xml-path}}
          - --output=/state/{{inputs.parameters.output-path}}
          - --objects-per-part={{inputs.parameters.rows-per-output}}
          - --gunzip-input
        env:
          - name: JAVA_OPTS
            value: "-Xmx2g -Xms2g"
        volumeMounts:
          - name: state-dir
            mountPath: /state
        resources:
          requests:
            memory: 2560Mi
            cpu: 1500m
          limits:
            memory: 2560Mi
            cpu: 1500m

    ## Uploads local files to a GCS bucket.
    - name: upload-to-gcs
      inputs:
        parameters:
          - name: local-path
          - name: gcs-bucket
          - name: gcs-path
          - name: key-secret-volume
          - name: key-secret-file
      container:
        image: google/cloud-sdk:slim
        command: [gsutil]
        args:
          - -m
          # Move the state dir to the persistent volume so we don't
          # lose track of progress across restarts.
          - -o
          - "GSUtil:state_dir=/state/.gsutil"
          # Point at the mounted SA credentials for auth.
          - -o
          - "Credentials:gs_service_key_file=/secrets/key.json"
          - rsync
          - -r
          - /state/{{inputs.parameters.local-path}}
          - gs://{{inputs.parameters.gcs-bucket}}/{{inputs.parameters.gcs-path}}
        volumeMounts:
          - name: state-dir
            mountPath: /state
          - name: "{{inputs.parameters.key-secret-volume}}"
            mountPath: /secrets
        env:
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: /secrets/{{inputs.parameters.key-secret-file}}
        resources:
          requests:
            memory: 1Gi
            cpu: 1500m
          limits:
            memory: 2Gi
            cpu: 2000m
      retryStrategy:
        limit: 32

